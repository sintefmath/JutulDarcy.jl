import{_ as r,c as l,a5 as t,j as a,a as o,G as s,B as n,o as p}from"./chunks/framework.uklXhCGU.js";const y=JSON.parse('{"title":"Multi-threading and MPI support","description":"","frontmatter":{},"headers":[],"relativePath":"man/advanced/mpi.md","filePath":"man/advanced/mpi.md","lastUpdated":null}'),d={name:"man/advanced/mpi.md"},u={class:"jldocstring custom-block",open:""};function c(h,e,m,g,f,v){const i=n("Badge");return p(),l("div",null,[e[3]||(e[3]=t('<h1 id="Multi-threading-and-MPI-support" tabindex="-1">Multi-threading and MPI support <a class="header-anchor" href="#Multi-threading-and-MPI-support" aria-label="Permalink to &quot;Multi-threading and MPI support {#Multi-threading-and-MPI-support}&quot;">​</a></h1><p>JutulDarcy can use threads by default, but advanced options can improve performance significantly for larger models.</p><h2 id="Overview-of-parallel-support" tabindex="-1">Overview of parallel support <a class="header-anchor" href="#Overview-of-parallel-support" aria-label="Permalink to &quot;Overview of parallel support {#Overview-of-parallel-support}&quot;">​</a></h2><p>There are two main ways of exploiting multiple cores in Jutul/JutulDarcy: Threads are automatically used for assembly and can be used for parts of the linear solve. If you require the best performance, you have to go to MPI where the linear solvers can use a parallel <a href="https://hypre.readthedocs.io/en/latest/solvers-boomeramg.html" target="_blank" rel="noreferrer">BoomerAMG preconditioner</a> via <a href="https://github.com/fredrikekre/HYPRE.jl" target="_blank" rel="noreferrer">HYPRE.jl</a>.</p><h3 id="MPI-parallelization" tabindex="-1">MPI parallelization <a class="header-anchor" href="#MPI-parallelization" aria-label="Permalink to &quot;MPI parallelization {#MPI-parallelization}&quot;">​</a></h3><p>MPI parallelizes all aspects of the solver using domain decomposition and allows a simulation to be divided between multiple nodes in e.g. a supercomputer. It is significantly more cumbersome to use than standard simulations as the program must be launched in MPI mode. This is typically a non-interactive process where you launch your MPI processes and once they complete the simulation the result is available on disk. The MPI parallel option uses a combination of MPI.jl, PartitionedArrays.jl and HYPRE.jl.</p><h3 id="Thread-parallelization" tabindex="-1">Thread parallelization <a class="header-anchor" href="#Thread-parallelization" aria-label="Permalink to &quot;Thread parallelization {#Thread-parallelization}&quot;">​</a></h3><p>JutulDarcy also supports threads. By defualt, this only parallelizes property evaluations and assembly of the linear system. For many problems, the linear solve is the limiting factor for performance.Using threads is automatic if you start Julia with multiple threads.</p><p>An experimental thread-parallel backend for matrices and linear algebra can be enabled by setting <code>backend=:csr</code> in the call to <a href="/JutulDarcy.jl/v0.2.32/man/highlevel#JutulDarcy.setup_reservoir_model"><code>setup_reservoir_model</code></a>. This backend provides additional features such as a parallel zero-overlap ILU(0) implementation and parallel apply for AMG, but these features are still work in progress.</p><h3 id="Mixed-mode-parallelism" tabindex="-1">Mixed-mode parallelism <a class="header-anchor" href="#Mixed-mode-parallelism" aria-label="Permalink to &quot;Mixed-mode parallelism {#Mixed-mode-parallelism}&quot;">​</a></h3><p>You can mix the two approaches: Adding multiple threads to each MPI process can use threads to speed up assembly and property evaluations.</p><h2 id="Solving-with-MPI-in-practice" tabindex="-1">Solving with MPI in practice <a class="header-anchor" href="#Solving-with-MPI-in-practice" aria-label="Permalink to &quot;Solving with MPI in practice {#Solving-with-MPI-in-practice}&quot;">​</a></h2><h3 id="Setting-up-the-environment" tabindex="-1">Setting up the environment <a class="header-anchor" href="#Setting-up-the-environment" aria-label="Permalink to &quot;Setting up the environment {#Setting-up-the-environment}&quot;">​</a></h3><p>Tou will have to set up an environment with the following packages under Julia 1.9+: <code>PartitionedArrays</code>, <code>MPI</code>, <code>JutulDarcy</code> and <code>HYPRE</code>. This is generally the best performing solver setup available, even if you are working in a shared memory environment.</p><h3 id="Writing-the-script" tabindex="-1">Writing the script <a class="header-anchor" href="#Writing-the-script" aria-label="Permalink to &quot;Writing the script {#Writing-the-script}&quot;">​</a></h3><p>Write your script as usual. The following options must then be set:</p><ul><li><p><a href="/JutulDarcy.jl/v0.2.32/man/highlevel#JutulDarcy.setup_reservoir_model"><code>setup_reservoir_model</code></a> should have the extra keyword argument <code>split_wells=true</code>. We also recommend <code>backend=:csr</code> for the best performance.</p></li><li><p><a href="/JutulDarcy.jl/v0.2.32/man/highlevel#JutulDarcy.simulate_reservoir"><code>simulate_reservoir</code></a> or <a href="/JutulDarcy.jl/v0.2.32/man/highlevel#JutulDarcy.setup_reservoir_simulator"><code>setup_reservoir_simulator</code></a> should get the optional argument <code>mode = :mpi</code></p></li></ul><p>You must then run the file using the approprioate <code>mpiexec</code> as described in the MPI.jl documentation. Specialized functions will be called by <code>simulate_reservoir</code> when this is the case. We document them here, even if we recommend using the high level version of this interface:</p><div class="warning custom-block"><p class="custom-block-title">Missing docstring.</p><p>Missing docstring for <code>setup_reservoir_simulator_parray</code>. Check Documenter&#39;s build log for details.</p></div>',19)),a("details",u,[a("summary",null,[e[0]||(e[0]=a("a",{id:"JutulDarcy.simulate_reservoir_parray",href:"#JutulDarcy.simulate_reservoir_parray"},[a("span",{class:"jlbinding"},"JutulDarcy.simulate_reservoir_parray")],-1)),e[1]||(e[1]=o()),s(i,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),e[2]||(e[2]=t('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">simulate_reservoir_parray</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(case, mode </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> :mpi</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; kwarg</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Run simulation with parray. This function is primarily for testing. <a href="/JutulDarcy.jl/v0.2.32/man/highlevel#JutulDarcy.simulate_reservoir"><code>simulate_reservoir</code></a> can do the same job by passing the correct mode.</p><p><a href="https://github.com/sintefmath/JutulDarcy.jl/blob/5d25ddf905677b3e27d734364f0cf6975aa99d89/src/ext.jl#L174-L179" target="_blank" rel="noreferrer">source</a></p>',3))]),e[4]||(e[4]=t('<h3 id="Limitations-for-running-in-MPI" tabindex="-1">Limitations for running in MPI <a class="header-anchor" href="#Limitations-for-running-in-MPI" aria-label="Permalink to &quot;Limitations for running in MPI {#Limitations-for-running-in-MPI}&quot;">​</a></h3><div class="tip custom-block"><p class="custom-block-title">Note</p><p>You should be familiar with the MPI programming model to use this feature. See <a href="https://juliaparallel.org/MPI.jl/stable/" target="_blank" rel="noreferrer">MPI.jl</a> for more details, and how MPI is handled in Julia specifically.</p></div><div class="tip custom-block"><p class="custom-block-title">Note</p><p>MPI consolidates results by writing files to disk. Unless you have a plan to work with the distributed states in-memory returned by the <code>simulate!</code> call, it is best to specify a <code>output_path</code> optional argument to <a href="/JutulDarcy.jl/v0.2.32/man/highlevel#JutulDarcy.setup_reservoir_simulator"><code>setup_reservoir_simulator</code></a>. After the simulation, that folder will contain output just as if you had run the case in serial.</p></div>',3))])}const k=r(d,[["render",c]]);export{y as __pageData,k as default};
