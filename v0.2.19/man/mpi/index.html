<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parallel solves with MPI · JutulDarcy.jl</title><meta name="title" content="Parallel solves with MPI · JutulDarcy.jl"/><meta property="og:title" content="Parallel solves with MPI · JutulDarcy.jl"/><meta property="twitter:title" content="Parallel solves with MPI · JutulDarcy.jl"/><meta name="description" content="Documentation for JutulDarcy.jl."/><meta property="og:description" content="Documentation for JutulDarcy.jl."/><meta property="twitter:description" content="Documentation for JutulDarcy.jl."/><meta property="og:url" content="https://sintefmath.github.io/JutulDarcy.jl/man/mpi/"/><meta property="twitter:url" content="https://sintefmath.github.io/JutulDarcy.jl/man/mpi/"/><link rel="canonical" href="https://sintefmath.github.io/JutulDarcy.jl/man/mpi/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="JutulDarcy.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">JutulDarcy.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../intro/">Getting started</a></li><li><a class="tocitem" href="../highlevel/">High-level functions</a></li><li><a class="tocitem" href="../input_files/">Input files</a></li><li><a class="tocitem" href="../forces/">Driving forces</a></li><li><a class="tocitem" href="../systems/">Supported physical systems</a></li><li><a class="tocitem" href="../wells/">Wells and controls</a></li><li><a class="tocitem" href="../solution/">Solving the equations</a></li><li><a class="tocitem" href="../primary/">Primary variables</a></li><li><a class="tocitem" href="../secondary/">Secondary variables (properties)</a></li><li><a class="tocitem" href="../parameters/">Parameters</a></li><li><a class="tocitem" href="../plotting/">Visualization</a></li></ul></li><li><span class="tocitem">Advanced usage</span><ul><li class="is-active"><a class="tocitem" href>Parallel solves with MPI</a><ul class="internal"><li><a class="tocitem" href="#Overview-of-parallel-support"><span>Overview of parallel support</span></a></li><li><a class="tocitem" href="#Solving-with-MPI-in-practice"><span>Solving with MPI in practice</span></a></li></ul></li><li><a class="tocitem" href="../compiled/">JutulDarcy.jl compiled app</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/intro/">Getting started</a></li><li><a class="tocitem" href="../../examples/two_phase_gravity_segregation/">Gravity segregation</a></li><li><a class="tocitem" href="../../examples/two_phase_buckley_leverett/">Two-phase Buckley-Leverett</a></li><li><a class="tocitem" href="../../examples/two_phase_unstable_gravity/">Gravity circulation with CPR preconditioner</a></li><li><a class="tocitem" href="../../examples/wells_intro/">Intro to wells</a></li><li><a class="tocitem" href="../../examples/five_spot_ensemble/">Quarter-five-spot with variation</a></li><li><a class="tocitem" href="../../examples/co2_brine_2d_vertical/">Intro to compositional flow</a></li><li><a class="tocitem" href="../../examples/compositional_5components/">Compositional with five components</a></li><li><a class="tocitem" href="../../examples/optimize_simple_bl/">Parameter optimization of Buckley-Leverett</a></li><li><a class="tocitem" href="../../examples/mrst_validation/">Validation of reservoir simulator</a></li></ul></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../../ref/jutul/">Jutul functions</a></li></ul></li><li><span class="tocitem">Additional information </span><ul><li><a class="tocitem" href="../../extras/refs/">References</a></li><li><a class="tocitem" href="../../extras/faq/">FAQ</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Advanced usage</a></li><li class="is-active"><a href>Parallel solves with MPI</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Parallel solves with MPI</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sintefmath/JutulDarcy.jl/blob/main/docs/src/man/mpi.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Parallel-solution-using-MPI.jl,-PartitionedArrays.jl-and-HYPRE.jl"><a class="docs-heading-anchor" href="#Parallel-solution-using-MPI.jl,-PartitionedArrays.jl-and-HYPRE.jl">Parallel solution using MPI.jl, PartitionedArrays.jl and HYPRE.jl</a><a id="Parallel-solution-using-MPI.jl,-PartitionedArrays.jl-and-HYPRE.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-solution-using-MPI.jl,-PartitionedArrays.jl-and-HYPRE.jl" title="Permalink"></a></h1><p>JutulDarcy can use threads by default, but advanced options can improve performance significantly for larger models.</p><h2 id="Overview-of-parallel-support"><a class="docs-heading-anchor" href="#Overview-of-parallel-support">Overview of parallel support</a><a id="Overview-of-parallel-support-1"></a><a class="docs-heading-anchor-permalink" href="#Overview-of-parallel-support" title="Permalink"></a></h2><p>There are two main ways of exploiting multiple cores in Jutul/JutulDarcy: Threads are automatically used for assembly and can be used for parts of the linear solve. If you require the best performance, you have to go to MPI where the linear solvers can use a parallel <a href="https://hypre.readthedocs.io/en/latest/solvers-boomeramg.html">BoomerAMG preconditioner</a> via <a href="https://github.com/fredrikekre/HYPRE.jl">HYPRE.jl</a>.</p><h3 id="MPI-parallelization"><a class="docs-heading-anchor" href="#MPI-parallelization">MPI parallelization</a><a id="MPI-parallelization-1"></a><a class="docs-heading-anchor-permalink" href="#MPI-parallelization" title="Permalink"></a></h3><p>MPI parallelizes all aspects of the solver using domain decomposition and allows a simulation to be divided between multiple nodes in e.g. a supercomputer. It is significantly more cumbersome to use than standard simulations as the program must be launched in MPI mode. This is typically a non-interactive process where you launch your MPI processes and once they complete the simulation the result is available on disk.</p><h3 id="Thread-parallelization"><a class="docs-heading-anchor" href="#Thread-parallelization">Thread parallelization</a><a id="Thread-parallelization-1"></a><a class="docs-heading-anchor-permalink" href="#Thread-parallelization" title="Permalink"></a></h3><p>JutulDarcy also supports threads. By defualt, this only parallelizes property evaluations and assembly of the linear system. For many problems, the linear solve is the limiting factor for performance.Using threads is automatic if you start Julia with multiple threads.</p><p>An experimental thread-parallel backend for matrices and linear algebra can be enabled by setting <code>backend=:csr</code> in the call to <a href="../highlevel/#JutulDarcy.setup_reservoir_model"><code>setup_reservoir_model</code></a>. This backend provides additional features such as a parallel zero-overlap ILU(0) implementation and parallel apply for AMG, but these features are still work in progress.</p><h3 id="Mixed-mode-parallelism"><a class="docs-heading-anchor" href="#Mixed-mode-parallelism">Mixed-mode parallelism</a><a id="Mixed-mode-parallelism-1"></a><a class="docs-heading-anchor-permalink" href="#Mixed-mode-parallelism" title="Permalink"></a></h3><p>You can mix the two approaches: Adding multiple threads to each MPI process can use threads to speed up assembly and property evaluations.</p><h2 id="Solving-with-MPI-in-practice"><a class="docs-heading-anchor" href="#Solving-with-MPI-in-practice">Solving with MPI in practice</a><a id="Solving-with-MPI-in-practice-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-with-MPI-in-practice" title="Permalink"></a></h2><h3 id="Setting-up-the-environment"><a class="docs-heading-anchor" href="#Setting-up-the-environment">Setting up the environment</a><a id="Setting-up-the-environment-1"></a><a class="docs-heading-anchor-permalink" href="#Setting-up-the-environment" title="Permalink"></a></h3><p>Tou will have to set up an environment with the following packages under Julia 1.9+: <code>PartitionedArrays</code>, <code>MPI</code>, <code>JutulDarcy</code> and <code>HYPRE</code>. This is generally the best performing solver setup available, even if you are working in a shared memory environment.</p><h3 id="Writing-the-script"><a class="docs-heading-anchor" href="#Writing-the-script">Writing the script</a><a id="Writing-the-script-1"></a><a class="docs-heading-anchor-permalink" href="#Writing-the-script" title="Permalink"></a></h3><p>Write your script as usual. The following options must then be set:</p><ul><li><a href="../highlevel/#JutulDarcy.setup_reservoir_model"><code>setup_reservoir_model</code></a> should have the extra keyword argument <code>split_wells=true</code>. We also recommend <code>backend=:csr</code> for the best performance.</li><li><a href="../highlevel/#JutulDarcy.simulate_reservoir"><code>simulate_reservoir</code></a> or <a href="../highlevel/#JutulDarcy.setup_reservoir_simulator"><code>setup_reservoir_simulator</code></a> should get the optional argument <code>mode = :mpi</code></li></ul><p>You must then run the file using the approprioate <code>mpiexec</code> as described in the MPI.jl documentation. Specialized functions will be called by <code>simulate_reservoir</code> when this is the case. We document them here, even if we recommend using the high level version of this interface:</p><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>setup_reservoir_simulator_parray</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>simulate_reservoir_parray</code>. Check Documenter&#39;s build log for details.</p></div></div><h3 id="Limitations-for-running-in-MPI"><a class="docs-heading-anchor" href="#Limitations-for-running-in-MPI">Limitations for running in MPI</a><a id="Limitations-for-running-in-MPI-1"></a><a class="docs-heading-anchor-permalink" href="#Limitations-for-running-in-MPI" title="Permalink"></a></h3><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>You should be familiar with the MPI programming model to use this feature. See <a href="https://juliaparallel.org/MPI.jl/stable/">MPI.jl</a> for more details, and how MPI is handled in Julia specifically.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>MPI consolidates results by writing files to disk. Unless you have a plan to work with the distributed states in-memory returned by the <code>simulate!</code> call, it is best to specify a <code>output_path</code> optional argument to <a href="../highlevel/#JutulDarcy.setup_reservoir_simulator"><code>setup_reservoir_simulator</code></a>. After the simulation, that folder will contain output just as if you had run the case in serial.</p></div></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../plotting/">« Visualization</a><a class="docs-footer-nextpage" href="../compiled/">JutulDarcy.jl compiled app »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Sunday 10 March 2024 20:15">Sunday 10 March 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
